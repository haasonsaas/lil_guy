---
author: Jonathan Haas
pubDate: '2025-05-26'
title: 'OCode: Why I Built My Own Claude Code (and Why You Might Too)'
description: >-
  OCode: Why I Built My Own Claude Code (and Why You Might Too): A few nights
  ago, I opened my Anthropic invoice.
featured: false
draft: false
tags:
  - engineering
  - product
  - strategy
  - transparency
  - open-source
  - developer-tools
  - ai
---

A few nights ago, I opened my Anthropic invoice. $602.14.

For _coding assistance_.

And not even during work hours‚ÄîI‚Äôm talking about an AI that times out at 2 a.m. with ‚Äúsomething went wrong‚Äù while I‚Äôm mid-refactor.

So yeah, I snapped.

## When SaaS Becomes a Tax

I‚Äôm a big believer in paying for good tools. But something‚Äôs broken when a month of occasional code suggestions costs more than your GitHub Copilot _and_ electricity bill combined.

Especially when all you‚Äôre doing is asking it to ‚Äúrun tests‚Äù and ‚Äúrename this function.‚Äù

So instead of paying another dime for glorified autocomplete, I did what any developer with too much coffee and not enough patience would do:

I built my own.

## Introducing OCode

OCode is my DIY Claude-for-code. Built on [Ollama](https://ollama.ai), runs locally, and understands your project like a senior engineer on espresso.

Same multi-file reasoning. No timeouts. Zero per-token billing.

And you can install it with one line:

````bash
curl -fsSL [https://raw.githubusercontent.com/haasonsaas/ocode/main/scripts/install.sh](https://raw.githubusercontent.com/haasonsaas/ocode/main/scripts/install.sh) | bash
```text

Because ‚Äúrun tests & commit‚Äù shouldn‚Äôt cost $600.

Let‚Äôs break down what OCode actually is, why I built it, and what it can do that shocked me.

---

## The Core Idea: Claude, but Local and Customizable

Most AI code tools are two things:

1. **Remote-first** (expensive, latency-prone, privacy-invasive)
1. **Opinionated black boxes** (you can‚Äôt tweak or inspect behavior)

OCode flips both.

It‚Äôs:

* **Terminal-native**
* **Runs entirely on your machine**
* **Speaks to Ollama models like Llama 3 or CodeLlama**
* **Fully inspectable and extendable**

Think of it as an open-source dev agent that actually understands your repo‚Äîand doesn‚Äôt leave you guessing why it renamed your files ‚Äúfinal*final*rewrite*v2.py‚Äù.

---

## Building It (a.k.a. The 10-Hour Hackathon With My Cats)

### Step 1: Pull Ollama + Llama 3

```bash
ollama pull llama3
```text

Turns out, these models can already handle multi-file prompts surprisingly well. The key is the scaffolding around them‚Äîsomething most ‚ÄúAI tools‚Äù either overcomplicate or completely ignore.

### Step 2: Create a Thin Shell Interface

I wired up a CLI wrapper using Python and Typer. The hard part wasn‚Äôt the CLI. It was deciding how to:

* Walk the repo
* Summarize context
* Preserve session state
* Route tasks to appropriate tools

### Step 3: Tool Layer = üß†

OCode‚Äôs architecture is simple but powerful. Every command goes through a query router that determines which ‚Äútools‚Äù to activate. Think:

* `grep*todos`
* `test*runner`
* `git*commit*summarizer`
* `refactor*engine`

The logic? Declarative YAML + some Python glue.

### Step 4: Make It Fast

Even locally, you want it snappy. So I added context strategies: minimal, targeted, full. Plus caching for file fingerprints. Net result?

< 2s cold start. Near-instant interaction after warmup.

---

## What OCode Can Actually Do

Here are just a few things I‚Äôve asked it to do in the last 48 hours:

* ‚ÄúRefactor the auth system across services‚Äù
* ‚ÄúFind all TODOs and resolve them‚Äù
* ‚ÄúAdd docstrings to all functions in utils.py‚Äù
* ‚ÄúWrite tests for UserRepository‚Äù
* ‚ÄúCommit changes with a smart message‚Äù

Each one handled with multi-step reasoning, zero setup, and no token anxiety.

---

## Why I‚Äôm Sticking With It

It‚Äôs not just that OCode saves me money.

It‚Äôs that it feels **mine**.

I can edit the tool layer. I can change the prompt format. I can route different tasks to different models. I can run it on a flight with no internet.

In a world where most AI tools feel like platforms trying to own you, OCode is a reminder that you can still own your own workflow.

---

## The Real Point

Look, I don‚Äôt expect everyone to ditch their cloud tools tomorrow. But if you‚Äôve ever looked at an AI invoice and thought, ‚ÄúThis is wild,‚Äù you‚Äôre not alone.

If you‚Äôve ever wished your dev assistant understood your repo *without* you copy-pasting three files into a chat window‚Äîyou‚Äôve got options.

And if you‚Äôve ever wanted something faster, cheaper, and more transparent than the big-box AI services?

Well, now you‚Äôve got a one-liner.

```bash
curl -fsSL [https://raw.githubusercontent.com/haasonsaas/ocode/main/scripts/install.sh](https://raw.githubusercontent.com/haasonsaas/ocode/main/scripts/install.sh) | bash
```text

And if you build something cool on top of it? Let me know. I built OCode to escape SaaS rent. But it might just be a better way to code.

---

**Made with a terminal window, two coffees, and two very confused cats.** üêà
````
